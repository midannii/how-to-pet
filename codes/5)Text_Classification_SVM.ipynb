{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class SVM\n",
    "- reuse https://github.com/TensorMSA/tensormsa_jupyter/blob/master/chap13_chatbot_lecture/5.Text_Classification_SVM.ipynb\n",
    "\n",
    "클래스가 2개 이상인 경우를 다중 클래스 분류(Multi-Class Classification)라 한다. 다중 클래스 분류 문제는 다음과 같이 여러개의 이진 클래스 분류(Binary Class Classification) 문제로 변환하여 해결한다.\n",
    "<img src=\"https://www.researchgate.net/profile/Anthony_Fleury/publication/220098164/figure/fig2/AS:305725600485382@1449902071844/Figure-2-Illustration-of-the-SVM-principle-and-of-the-one-versus-one-multiclass.png\" width=\"600\" height=\"600\" />\n",
    "<br>\n",
    "#### OvR (One-vs-the-Rest)\n",
    "K 개의 타겟 클래스가 존재하는 경우,\n",
    "각각의 클래스에 대해 표본이 속하는지 속하지 않는지의 이진 클래스 분류 문제를 풀고\n",
    "판결 기준값이 가장 큰 클래스를 선택 OneVsRestClassifier 클래스\n",
    "<img src=\"https://pythonprogramming.net/static/images/machine-learning/one-vs-rest-svm.png\" width=\"300\" height=\"300\" />\n",
    "<br>\n",
    "#### OvO (One-Vs-One)\n",
    "K 개의 타겟 클래스가 존재하는 경우,\n",
    "이 중 2개의 클래스 조합을 선택하여  K(K−1)/2K(K−1)/2 개의 이진 클래스 분류 문제를 풀고\n",
    "투표를 통해 가장 많은 표를 얻은 클래스를 선택\n",
    "실제로는 정규화된 판결 기준값을 이용 OneVsOneClassifier 클래스\n",
    "<img src=\"https://pythonprogramming.net/static/images/machine-learning/one-vs-one-svm.png\" width=\"300\" height=\"300\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3가지의 의도로 Text를 분류해보자 (특성질문, 질병질문, 접종질문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "\n",
    "train_data_list =  {\n",
    "                   'encode' : ['말티즈 성격 어때?','자꾸 털이 빠지고 기침을 하네 ㅠㅠ','지금8개월인데예방접종뭐해야해?'],\n",
    "                'decode' : ['0','1','2']\n",
    "                   }\n",
    "\n",
    "embed_type = 'onehot'\n",
    "encode_length = 8 #문장의 최대 길이 나머지는 Padding로 채움\n",
    "vector_size = 50\n",
    "label_size = 3 #Label의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_vectorize(bucket, x):\n",
    "    #W2V의 Vocab의 해당 index값을 onehot으로 만듬\n",
    "    np.put(bucket, model.wv.index2word.index(x),1)\n",
    "    return bucket\n",
    "\n",
    "def embed(data) : \n",
    "    mecab = Mecab('/usr/local/lib/mecab/dic/mecab-ko-dic')\n",
    "    inputs = []\n",
    "#   labels = []\n",
    "    for encode_raw in data['encode'] : \n",
    "        encode_raw = mecab.morphs(encode_raw)\n",
    "        encode_raw = list(map(lambda x : encode_raw[x] if x < len(encode_raw) else '#', range(encode_length)))\n",
    "        if(embed_type == 'onehot') :\n",
    "            bucket = np.zeros(vector_size, dtype=float).copy()\n",
    "            input = np.array(list(map(lambda x : onehot_vectorize(bucket, x) if x in model.wv.index2word else np.zeros(vector_size,dtype=float) , encode_raw)))\n",
    "        inputs.append(input.flatten())\n",
    "        print(encode_raw)\n",
    "#     for decode_raw in data['decode']: \n",
    "#         label = np.zeros(label_size, dtype=float)\n",
    "#         np.put(label, decode_raw, 1)\n",
    "#         labels.append(label)\n",
    "    return inputs #labels\n",
    "\n",
    "#X, y = embed(train_data_list) #Encode와 Decode Data를 X와 y값에 Vector값을 담음\n",
    "X = embed(train_data_list) #Encode와 Decode Data를 X와 y값에 Vector값을 담음\n",
    "y = train_data_list['decode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]]),\n",
       " array([[0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 50)\n",
      "(4, 50)\n",
      "(4, 50)\n"
     ]
    }
   ],
   "source": [
    "for i in X: print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def train_vector_model(str_buf):\n",
    "    mecab = Mecab('/usr/local/lib/mecab/dic/mecab-ko-dic')\n",
    "    str_buf = train_data_list['encode']\n",
    "    #mecab로 POS Tagging\n",
    "    pos1 = mecab.pos(''.join(str_buf))\n",
    "    #문장별로 list로 나눔 마침표등이 존재시 줄바꾸기 (문장이길경우)\n",
    "    pos2 = ' '.join(list(map(lambda x : '\\n' if x[1] in ['SF'] else x[0], pos1))).split('\\n')\n",
    "    #단어구성을 위한 형태소단위 문장 쪼개기 \n",
    "    morphs = list(map(lambda x : mecab.morphs(x) , pos2))\n",
    "    model = word2vec.Word2Vec(size=vector_size, window=2, min_count=1)\n",
    "    model.build_vocab(morphs)\n",
    "    model.train(morphs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=23, size=50, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# W2V Vector 모델 생성\n",
    "model = train_vector_model(temp)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['말', '티즈', '성격', '어때요', '자꾸', '털', '이', '빠지', '고', '기침', '을', '하', '네', 'ㅠㅠ', '지금', '8', '개월', '인데', '예방', '접종', '뭐', '해야', '해']\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X2 = tf.convert_to_tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 50\n"
     ]
    }
   ],
   "source": [
    "nsamples = len(X)\n",
    "nx, ny = X[0].shape\n",
    "print(nsamples, nx, ny)\n",
    "X3 = tf.reshape(X2,(nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 200])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "clf.fit(X3, y) \n",
    "# print(clf.predict([[2, 2]]))\n",
    "print(clf.predict(X3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
